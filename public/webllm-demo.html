<!DOCTYPE html>
<html lang="nl">
  <head>
    <meta charset="UTF-8" />
    <title>WebLLM chatdemo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body {
        font-family: system-ui, sans-serif;
        margin: 12px;
        line-height: 1.4;
        background: #020617;
        color: #e5e7eb;
      }
      h3 {
        margin-top: 0;
        margin-bottom: 4px;
      }
      #status {
        font-size: 0.9rem;
        color: #e5e7eb;
        margin-bottom: 8px;
      }
      .chat {
        border: 1px solid #1f2937;
        border-radius: 10px;
        padding: 10px;
        height: 260px;
        overflow-y: auto;
        background: #020617;
        display: flex;
        flex-direction: column;
        gap: 6px;
      }
      .msg-row {
        display: flex;
        width: 100%;
      }
      .msg {
        max-width: 80%;
        padding: 8px 11px;
        border-radius: 12px;
        font-size: 0.9rem;
        word-wrap: break-word;
        white-space: pre-wrap;
      }
      .msg.user {
        margin-left: auto;
        background: #0f172a;
        border-bottom-right-radius: 2px;
        text-align: right;
      }
      .msg.bot {
        margin-right: auto;
        background: #111827;
        border-bottom-left-radius: 2px;
      }
      .row {
        display: flex;
        gap: 8px;
        margin-top: 10px;
      }
      input {
        flex: 1;
        padding: 10px;
        border-radius: 10px;
        border: 1px solid #334155;
        background: #0f172a;
        color: #e5e7eb;
        box-sizing: border-box;
      }
      input::placeholder {
        color: #64748b;
      }
      button {
        padding: 8px 14px;
        border-radius: 10px;
        border: 1px solid #334155;
        background: #1e293b;
        color: #e5e7eb;
        cursor: pointer;
        transition: background 0.12s ease, transform 0.12s ease;
        white-space: nowrap;
      }
      button:hover:not(:disabled) {
        background: #334155;
        transform: translateY(-1px);
      }
      button:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }
      .hint {
        font-size: 0.8rem;
        color: #94a3b8;
        margin-top: 6px;
      }
    </style>
  </head>
  <body>
    <h3>Lokale LLM via WebGPU</h3>
    <div id="status">Status: model laden (eerste keer kan 20–40s duren)…</div>

    <div id="chat" class="chat"></div>

    <div class="row">
      <input
        id="prompt"
        placeholder="Voorbeeld: Explain what Edge AI is in one sentence."
      />
      <button id="go" disabled>Genereer</button>
    </div>

    <p class="hint">
      Deze demo gebruikt een klein instructiemodel
      (<code>LaMini-Flan-T5-77M</code>) via Transformers.js. De generatie
      gebeurt volledig in je browser (Edge&nbsp;AI). Druk op Enter om je vraag
      te verzenden.
    </p>

    <script type="module">
      import {
        pipeline,
        env,
      } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers/dist/transformers.min.js'

      // Cache uit om oude corrupte bestanden te vermijden
      env.useBrowserCache = false
      env.allowLocalModels = false
      env.allowRemoteModels = true

      const statusEl = document.getElementById('status')
      const chatEl = document.getElementById('chat')
      const promptEl = document.getElementById('prompt')
      const goBtn = document.getElementById('go')

      function addMessage(text, who) {
        const row = document.createElement('div')
        row.className = 'msg-row'

        const bubble = document.createElement('div')
        bubble.className = 'msg ' + who
        bubble.textContent = text

        row.appendChild(bubble)
        chatEl.appendChild(row)
        chatEl.scrollTop = chatEl.scrollHeight
      }

      let generator = null

      // Model laden (instruction-tuned text2text model)
      ;(async () => {
        try {
          statusEl.textContent =
            'Status: model laden (eerste keer kan 20–40s duren)…'

          generator = await pipeline(
            'text-generation',
            'Xenova/Qwen1.5-0.5B-Chat',
            { device: 'webgpu' } // als WebGPU niet beschikbaar is, valt hij terug op WASM/CPU
          )

          statusEl.textContent =
            'Status: klaar – model draait lokaal (WebGPU indien beschikbaar).'
          goBtn.disabled = false
        } catch (err) {
          console.error(err)
          statusEl.textContent =
            'Kon het model niet laden (mogelijk geblokkeerde download of netwerkprobleem).'
          addMessage('Fout bij laden model: ' + err.message, 'bot')
        }
      })()

      async function runGeneration() {
        const promptEl = document.getElementById('prompt')
        const userText = promptEl.value.trim()
        if (!userText) return

        addMessage(userText, 'user')
        promptEl.value = ''
        promptEl.focus()

        const statusEl = document.getElementById('status')
        const goBtn = document.getElementById('go')

        if (!generator) {
          addMessage(
            'Model is nog aan het laden, probeer het over enkele seconden opnieuw.',
            'bot'
          )
          return
        }

        goBtn.disabled = true
        statusEl.textContent = 'Status: bezig met genereren…'

        // Chat template volgens de officiële Qwen-voorbeelden
        const messages = [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: userText },
        ]

        const chatText = generator.tokenizer.apply_chat_template(messages, {
          tokenize: false,
          add_generation_prompt: true,
        })

        try {
          const output = await generator(chatText, {
            max_new_tokens: 128,
            do_sample: true,
            temperature: 0.7,
            return_full_text: false,
          })

          const answer = (output[0]?.generated_text || '').trim()
          addMessage(answer || '[Geen zinvol antwoord]', 'bot')
        } catch (err) {
          console.error(err)
          addMessage('Fout tijdens generatie: ' + err.message, 'bot')
        } finally {
          goBtn.disabled = false
          statusEl.textContent =
            'Status: klaar – model draait lokaal (WebGPU indien beschikbaar).'
        }
      }

      goBtn.addEventListener('click', runGeneration)

      // Enter om te verzenden (Shift+Enter voor nieuwe regel)
      promptEl.addEventListener('keydown', (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
          e.preventDefault()
          runGeneration()
        }
      })
    </script>
  </body>
</html>
